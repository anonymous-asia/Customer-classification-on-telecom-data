{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Customer classification-telecom data.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ury75V3nYj8"
      },
      "source": [
        "1. Open and look through the data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGJ5N5j2nYj9",
        "outputId": "76bcb8d2-c0e9-4c8f-d303-ca952c71fb66"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df=pd.read_csv('/datasets/users_behavior.csv')\n",
        "print(df.info())\n",
        "print(df.head(20))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3214 entries, 0 to 3213\n",
            "Data columns (total 5 columns):\n",
            "calls       3214 non-null float64\n",
            "minutes     3214 non-null float64\n",
            "messages    3214 non-null float64\n",
            "mb_used     3214 non-null float64\n",
            "is_ultra    3214 non-null int64\n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 125.7 KB\n",
            "None\n",
            "    calls  minutes  messages   mb_used  is_ultra\n",
            "0    40.0   311.90      83.0  19915.42         0\n",
            "1    85.0   516.75      56.0  22696.96         0\n",
            "2    77.0   467.66      86.0  21060.45         0\n",
            "3   106.0   745.53      81.0   8437.39         1\n",
            "4    66.0   418.74       1.0  14502.75         0\n",
            "5    58.0   344.56      21.0  15823.37         0\n",
            "6    57.0   431.64      20.0   3738.90         1\n",
            "7    15.0   132.40       6.0  21911.60         0\n",
            "8     7.0    43.39       3.0   2538.67         1\n",
            "9    90.0   665.41      38.0  17358.61         0\n",
            "10   82.0   560.51      20.0   9619.53         1\n",
            "11   45.0   344.32      13.0  19898.81         0\n",
            "12   51.0   437.13      61.0  21523.58         0\n",
            "13   56.0   433.07      16.0  16702.36         0\n",
            "14  108.0   587.90       0.0  14406.50         1\n",
            "15    6.0    22.13       0.0   2710.09         0\n",
            "16    2.0    18.73       0.0    588.89         0\n",
            "17   26.0   163.62       4.0  16870.34         0\n",
            "18   79.0   532.62      90.0  19908.31         0\n",
            "19   49.0   341.67      81.0  11770.28         1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W09GXhc5nYj-"
      },
      "source": [
        "2. Split the source data into a training set, a validation set, and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLMVfComnYj_"
      },
      "source": [
        "#defining the features and target for train, valid and test data\n",
        "\n",
        "train,df_test=train_test_split(df,test_size=0.2, random_state=12345)\n",
        "df_train, df_valid=train_test_split(train, test_size=0.2, random_state=12345)\n",
        "\n",
        "features_train=df_train.drop(['is_ultra'], axis=1)\n",
        "target_train=df_train['is_ultra']\n",
        "\n",
        "features_test=df_test.drop(['is_ultra'], axis=1)\n",
        "target_test=df_test['is_ultra']\n",
        "\n",
        "features_valid=df_valid.drop(['is_ultra'], axis=1)\n",
        "target_valid=df_valid['is_ultra']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6DDs8vlnYkA"
      },
      "source": [
        "3. Investigate the quality of different models by changing hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwkEsQJtnYkA",
        "outputId": "555cc19d-3838-4ca5-a832-771ad6d77277"
      },
      "source": [
        "#hyperparameter tuning for the Decision Tree\n",
        "\n",
        "for depth in range(1,6):\n",
        "    model_dt=DecisionTreeClassifier(max_depth=depth,random_state=12345)\n",
        "    model_dt.fit(features_train, target_train)\n",
        "    score_dt=model_dt.score(features_valid, target_valid)\n",
        "    print(\"max_depth:\",depth,\":\",score_dt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_depth: 1 : 0.7223300970873786\n",
            "max_depth: 2 : 0.7475728155339806\n",
            "max_depth: 3 : 0.7553398058252427\n",
            "max_depth: 4 : 0.7533980582524272\n",
            "max_depth: 5 : 0.7572815533980582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmgtjPnNnYkA",
        "outputId": "3fad7324-498e-4400-860b-cd4d2a34b447"
      },
      "source": [
        "#hyperparameter tuning for the Random Forest\n",
        "\n",
        "for estim in range(10, 61, 10):\n",
        "        model_RF = RandomForestClassifier(n_estimators=estim, random_state=12345)\n",
        "        model_RF.fit(features_train, target_train)\n",
        "        score_RF=model_RF.score(features_valid, target_valid)\n",
        "        print(\"n_estimators =\", estim, \":\", score_RF)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_estimators = 10 : 0.7650485436893204\n",
            "n_estimators = 20 : 0.7728155339805826\n",
            "n_estimators = 30 : 0.7766990291262136\n",
            "n_estimators = 40 : 0.7786407766990291\n",
            "n_estimators = 50 : 0.7786407766990291\n",
            "n_estimators = 60 : 0.7786407766990291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4sc8pc9nYkB",
        "outputId": "a40834b2-b797-4886-b08b-dd904c0b08d3"
      },
      "source": [
        "# applying Logistic regression\n",
        "\n",
        "model_lr=LogisticRegression(random_state=12345)\n",
        "model_lr.fit(features_train, target_train)\n",
        "score_lr=model_lr.score(features_valid, target_valid)\n",
        "print(score_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7203883495145631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jexJJSEnYkB"
      },
      "source": [
        "Based on the score, Randomforest with n-estimator=40 looks like the best model with an accuracy of 77.86%. Since n-estimators with 40, 50 and 60 have the same value and as we increase the n-estimators it effect the model processing time, hence I will consider n-estimator=40."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8HFmblnYkC"
      },
      "source": [
        "4. Check the quality of the model using the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBvZEV37nYkC",
        "outputId": "948363ff-6f38-44e6-fe0e-b9b5a67b8e44"
      },
      "source": [
        "model_test=RandomForestClassifier(n_estimators=40, random_state=12345)\n",
        "model_test.fit(features_train, target_train)\n",
        "score_test=model_test.score(features_test, target_test)\n",
        "print(score_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7884914463452566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Yddi5wnYkC"
      },
      "source": [
        "The test set has a higher accuracy then the validation set by ~1%"
      ]
    }
  ]
}